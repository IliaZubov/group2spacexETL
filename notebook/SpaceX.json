{
	"name": "SpaceX",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "spacexlarge",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "c0f36f84-b2eb-4a95-987f-196ccb313de4"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/23b183d5-a30f-46b8-b418-ad060fb67787/resourceGroups/Group2-ETL-Proj/providers/Microsoft.Synapse/workspaces/group2spacex/bigDataPools/spacexlarge",
				"name": "spacexlarge",
				"type": "Spark",
				"endpoint": "https://group2spacex.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spacexlarge",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.5",
				"nodeCount": 10,
				"cores": 16,
				"memory": 112,
				"automaticScaleJobs": true
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"import requests, json\n",
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.functions import hash, col, crc32, explode, explode_outer\n",
					"import pandas as pd\n",
					"\n",
					"spark = SparkSession.builder.appName(\"launches_data\").getOrCreate()\n",
					"\n",
					"launches_url = \"https://api.spacexdata.com/v4/launches\"\n",
					"\n",
					"headers = {\n",
					"    \"Content-Type\": \"application/json\"}\n",
					"\n",
					"response = requests.get(launches_url).json()\n",
					"\n",
					"json_rdd = sc.parallelize([json.dumps(record) for record in response])\n",
					"\n",
					"df_raw = spark.read.json(json_rdd)\n",
					""
				],
				"execution_count": 79
			},
			{
				"cell_type": "code",
				"source": [
					"df_fail = df_raw.withColumn(\n",
					"    \"failure_reason\",  col(\"failures\").getItem(0).reason\n",
					").withColumn(\n",
					"    \"failure_time\",    col(\"failures\").getItem(0).time\n",
					").withColumn(\n",
					"    \"failure_altitude\",col(\"failures\").getItem(0).altitude\n",
					")\n",
					"df1 = df_fail.withColumn(\"core\", explode(\"cores\"))\n",
					"df2 = df1.withColumn(\"payload_id\", explode(\"payloads\"))\n",
					"df_spark_launches = df2.select(\n",
					"    \"id\",\n",
					"    \"flight_number\",\n",
					"    \"name\",\n",
					"    \"date_utc\",\n",
					"    \"rocket\",\n",
					"    \"success\",\n",
					"    \"details\",\n",
					"    \"launchpad\",\n",
					"    col(\"fairings.reused\").alias(\"fairings_reused\"),\n",
					"    col(\"fairings.recovered\").alias(\"fairings_recovered\"),\n",
					"    col(\"fairings.ships\").alias(\"fairings_ships\"),\n",
					"    \"payload_id\",\n",
					"    col(\"core.core\").alias(\"core_id\"),\n",
					"    col(\"core.flight\").alias(\"core_flight\"),\n",
					"    col(\"core.gridfins\").alias(\"core_gridfins\"),\n",
					"    col(\"core.legs\").alias(\"core_legs\"),\n",
					"    col(\"core.reused\").alias(\"core_reused\"),\n",
					"    col(\"core.landing_attempt\").alias(\"core_landing_attempt\"),\n",
					"    col(\"core.landing_success\").alias(\"core_landing_success\"),\n",
					"    col(\"core.landing_type\").alias(\"core_landing_type\"),\n",
					"    col(\"core.landpad\").alias(\"core_landpad\"),\n",
					"    \"failure_reason\",\n",
					"    \"failure_time\",\n",
					"    \"failure_altitude\"\n",
					")\n",
					"\n",
					"for c in df_spark_launches.columns:\n",
					"    new_c = c.replace(\".\", \"_\").replace(\" \", \"_\").replace(\"-\", \"_\")\n",
					"    df_spark_launches = df_spark_launches.withColumnRenamed(c, new_c)\n",
					""
				],
				"execution_count": 80
			},
			{
				"cell_type": "code",
				"source": [
					"df_spark_launches = df_spark_launches.withColumn(\"fairings_ships_id\", explode_outer(\"fairings_ships\"))"
				],
				"execution_count": 81
			},
			{
				"cell_type": "code",
				"source": [
					"df_spark_launches = df_spark_launches.drop(\"fairings_ships\")"
				],
				"execution_count": 82
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"display(df_spark_launches)"
				],
				"execution_count": 83
			},
			{
				"cell_type": "code",
				"source": [
					"rename_map = {\n",
					"    'core': 'core_id', \n",
					"    'flight': 'core_flight', \n",
					"    'gridfins': 'core_grid_fins', \n",
					"    'legs': 'core_legs', \n",
					"    'reused': 'core_reused', \n",
					"    'landing_attempt': 'core_landing_attempt', \n",
					"    'landing_success': 'core_landing_success', \n",
					"    'landing_type':'core_landing_type', \n",
					"    'landpad':'core_landpad',\n",
					"    'id': 'launch_id',\n",
					"    'name': 'launch_name',\n",
					"    'date_utc': 'launch_date_utc',\n",
					"    'rocket': 'rocket_id',\n",
					"    'success': 'launch_success',\n",
					"    'details': 'launch_details',\n",
					"    'launchpad': 'launchpad_id'\n",
					"}\n",
					"\n",
					"def rename_columns(df, mapping):\n",
					"    for old, new in mapping.items():\n",
					"        if old in df.columns:\n",
					"            df = df.withColumnRenamed(old, new)\n",
					"    return df\n",
					"\n",
					"df_spark_launches = rename_columns(df_spark_launches, rename_map)"
				],
				"execution_count": 84
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"display(df_spark_launches)"
				],
				"execution_count": 85
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"fact_launches = df_spark_launches.withColumns(\n",
					"    {\n",
					"        'core_id': crc32('core_id'), \n",
					"        'launch_id': crc32('launch_id'), \n",
					"        'core_landpad_id': crc32('core_landpad'), \n",
					"        'rocket_id': crc32('rocket_id'), \n",
					"        'launchpad_id': crc32('launchpad_id'), \n",
					"        'payload_id': crc32('payload_id'),\n",
					"        'fairing_ships_id': crc32('fairings_ships_id')\n",
					"    }\n",
					")\n",
					"display(fact_launches)"
				],
				"execution_count": 86
			},
			{
				"cell_type": "code",
				"source": [
					"cores_url = \"https://api.spacexdata.com/v4/cores\"\n",
					"\n",
					"headers = {\n",
					"    \"Content-Type\": \"application/json\"}\n",
					"\n",
					"response = requests.get(cores_url).json()\n",
					"\n",
					"json_rdd = sc.parallelize([json.dumps(record) for record in response])\n",
					"\n",
					"df_cores_raw = spark.read.json(json_rdd)"
				],
				"execution_count": 87
			},
			{
				"cell_type": "code",
				"source": [
					"df_cores_raw = df_cores_raw.drop('launches', 'serial')\n",
					"df_cores_raw = (df_cores_raw\n",
					"    .withColumnRenamed(\"id\", \"core_id\")\n",
					"    .withColumnRenamed(\"status\", \"core_status\")\n",
					"    .withColumnRenamed(\"serial\", \"core_serial\")\n",
					"    .withColumnRenamed(\"block\", \"core_block\")\n",
					")\n",
					""
				],
				"execution_count": 88
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"dim_cores = df_cores_raw.withColumn(\"core_id\", crc32(\"core_id\"))\n",
					"display(df_dim_cores)"
				],
				"execution_count": 89
			},
			{
				"cell_type": "code",
				"source": [
					"dim_cores.groupBy(\"core_id\") \\\n",
					"  .count() \\\n",
					"  .show()"
				],
				"execution_count": 90
			},
			{
				"cell_type": "code",
				"source": [
					"dim_cores.write.mode(\"overwrite\").saveAsTable(\"default.dim_cores\")\n",
					"fact_launches.write.mode(\"overwrite\").saveAsTable(\"default.fact_launches\")"
				],
				"execution_count": 91
			}
		]
	}
}