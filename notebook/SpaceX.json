{
	"name": "SpaceX",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "spacexlarge",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "471d34ad-ae9c-4b58-a50a-25c6c13d2d1b"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/23b183d5-a30f-46b8-b418-ad060fb67787/resourceGroups/Group2-ETL-Proj/providers/Microsoft.Synapse/workspaces/group2spacex/bigDataPools/spacexlarge",
				"name": "spacexlarge",
				"type": "Spark",
				"endpoint": "https://group2spacex.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spacexlarge",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.5",
				"nodeCount": 10,
				"cores": 16,
				"memory": 112,
				"automaticScaleJobs": true
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"import requests, json\n",
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.functions import hash, col, crc32, explode, explode_outer\n",
					"import pandas as pd\n",
					"\n",
					"spark = SparkSession.builder.appName(\"launches_data\").getOrCreate()\n",
					"\n",
					"launches_url = \"https://api.spacexdata.com/v4/launches\"\n",
					"\n",
					"headers = {\n",
					"    \"Content-Type\": \"application/json\"}\n",
					"\n",
					"response = requests.get(launches_url).json()\n",
					"\n",
					"json_rdd = sc.parallelize([json.dumps(record) for record in response])\n",
					"\n",
					"df_raw = spark.read.json(json_rdd)\n",
					""
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"source": [
					"df_fail = df_raw.withColumn(\n",
					"    \"failure_reason\",  col(\"failures\").getItem(0).reason\n",
					").withColumn(\n",
					"    \"failure_time\",    col(\"failures\").getItem(0).time\n",
					").withColumn(\n",
					"    \"failure_altitude\",col(\"failures\").getItem(0).altitude\n",
					")\n",
					"df1 = df_fail.withColumn(\"core\", explode(\"cores\"))\n",
					"df2 = df1.withColumn(\"payload_id\", explode(\"payloads\"))\n",
					"df_spark_launches = df2.select(\n",
					"    \"id\",\n",
					"    \"flight_number\",\n",
					"    \"name\",\n",
					"    \"date_utc\",\n",
					"    \"rocket\",\n",
					"    \"success\",\n",
					"    \"details\",\n",
					"    \"launchpad\",\n",
					"    col(\"fairings.reused\").alias(\"fairings_reused\"),\n",
					"    col(\"fairings.recovered\").alias(\"fairings_recovered\"),\n",
					"    col(\"fairings.ships\").alias(\"fairings_ships\"),\n",
					"    \"payload_id\",\n",
					"    col(\"core.core\").alias(\"core_id\"),\n",
					"    col(\"core.flight\").alias(\"core_flight\"),\n",
					"    col(\"core.gridfins\").alias(\"core_gridfins\"),\n",
					"    col(\"core.legs\").alias(\"core_legs\"),\n",
					"    col(\"core.reused\").alias(\"core_reused\"),\n",
					"    col(\"core.landing_attempt\").alias(\"core_landing_attempt\"),\n",
					"    col(\"core.landing_success\").alias(\"core_landing_success\"),\n",
					"    col(\"core.landing_type\").alias(\"core_landing_type\"),\n",
					"    col(\"core.landpad\").alias(\"core_landpad\"),\n",
					"    \"failure_reason\",\n",
					"    \"failure_time\",\n",
					"    \"failure_altitude\"\n",
					")\n",
					"\n",
					"for c in df_spark_launches.columns:\n",
					"    new_c = c.replace(\".\", \"_\").replace(\" \", \"_\").replace(\"-\", \"_\")\n",
					"    df_spark_launches = df_spark_launches.withColumnRenamed(c, new_c)\n",
					""
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"source": [
					"df_spark_launches = df_spark_launches.withColumn(\"fairings_ships_id\", explode_outer(\"fairings_ships\"))"
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"source": [
					"df_spark_launches = df_spark_launches.drop(\"fairings_ships\")"
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"display(df_spark_launches)"
				],
				"execution_count": 5
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_fact_launches = pd.json_normalize(\n",
					"    launches_data,\n",
					"    record_path=['cores'], \n",
					"    meta=[\n",
					"        'id',\n",
					"        'flight_number',\n",
					"        'name',\n",
					"        'date_utc',\n",
					"        'rocket',\n",
					"        'success',\n",
					"        'details',\n",
					"        'launchpad',\n",
					"        ['fairings', 'reused'],\n",
					"        ['fairings', 'recovered'],\n",
					"        ['fairings', 'ships'],\n",
					"        'payloads'  \n",
					"    ],\n",
					"    sep='_',\n",
					"    errors='ignore'\n",
					")\n",
					"\n",
					"df_fact_launches = df_fact_launches.explode('payloads').reset_index(drop=True)\n",
					"\n",
					"df_fact_launches.rename(columns={'payloads': 'payload_id'}, inplace=True)\n",
					"\n",
					"df_fact_launches['failure_reason'] = df_fact_launches['id'].map(\n",
					"    lambda x: next((launch.get('failures')[0]['reason']\n",
					"                    for launch in launches_data\n",
					"                    if launch['id'] == x and launch.get('failures')), None)\n",
					")\n",
					"\n",
					"df_fact_launches['failure_altitude'] = df_fact_launches['id'].map(\n",
					"    lambda x: next((launch.get('failures')[0]['altitude']\n",
					"                    for launch in launches_data\n",
					"                    if launch['id'] == x and launch.get('failures')), None)\n",
					")\n",
					"\n",
					"df_fact_launches['failure_time'] = df_fact_launches['id'].map(\n",
					"    lambda x: next((launch.get('failures')[0]['time']\n",
					"                    for launch in launches_data\n",
					"                    if launch['id'] == x and launch.get('failures')), None)\n",
					")\n",
					"\n",
					"df_fact_launches = df_fact_launches.loc[:, ~df_fact_launches.columns.str.startswith('links')]\n",
					"df_fact_launches.columns = df_fact_launches.columns.str.replace(r'\\W+', '_', regex=True)\n",
					"\n",
					"\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"rename_map = {\n",
					"    'core': 'core_id', \n",
					"    'flight': 'core_flight', \n",
					"    'gridfins': 'core_grid_fins', \n",
					"    'legs': 'core_legs', \n",
					"    'reused': 'core_reused', \n",
					"    'landing_attempt': 'core_landing_attempt', \n",
					"    'landing_success': 'core_landing_success', \n",
					"    'landing_type':'core_landing_type', \n",
					"    'landpad':'core_landpad',\n",
					"    'id': 'launch_id',\n",
					"    'name': 'launch_name',\n",
					"    'date_utc': 'launch_date_utc',\n",
					"    'rocket': 'rocket_id',\n",
					"    'success': 'launch_success',\n",
					"    'details': 'launch_details',\n",
					"    'launchpad': 'launchpad_id'\n",
					"}\n",
					"\n",
					"def rename_columns(df, mapping):\n",
					"    for old, new in mapping.items():\n",
					"        if old in df.columns:\n",
					"            df = df.withColumnRenamed(old, new)\n",
					"    return df\n",
					"\n",
					"df_spark_launches = rename_columns(df_spark_launches, rename_map)"
				],
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"display(df_spark_launches)"
				],
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"fact_launches = df_spark_launches.withColumns(\n",
					"    {\n",
					"        'core_id': crc32('core_id'), \n",
					"        'launch_id': crc32('launch_id'), \n",
					"        'core_landpad_id': crc32('core_landpad'), \n",
					"        'rocket_id': crc32('rocket_id'), \n",
					"        'launchpad_id': crc32('launchpad_id'), \n",
					"        'payload_id': crc32('payload_id'),\n",
					"        'fairing_ships_id': crc32('fairings_ships_id')\n",
					"    }\n",
					")\n",
					"display(fact_launches)"
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"cores_url = \"https://api.spacexdata.com/v4/cores\"\n",
					"headers = {\n",
					"    \"Content-Type\": \"application/json\"}\n",
					"\n",
					"response = requests.get(cores_url)\n",
					"cores_data = response.json()"
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"source": [
					"cores_url = \"https://api.spacexdata.com/v4/cores\"\n",
					"\n",
					"headers = {\n",
					"    \"Content-Type\": \"application/json\"}\n",
					"\n",
					"response = requests.get(cores_url).json()\n",
					"\n",
					"json_rdd = sc.parallelize([json.dumps(record) for record in response])\n",
					"\n",
					"df_cores_raw = spark.read.json(json_rdd)"
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"source": [
					"df_dim_cores = pd.json_normalize(cores_data)\n",
					"df_dim_cores.drop('launches', axis=1, inplace=True)\n",
					"df_dim_cores.rename(columns={'id': 'core_id', 'status': 'core_status', 'serial': 'core_serial', 'block': 'core_block'}, inplace=True)\n",
					"df_dim_cores"
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"spark_dim_cores = spark.createDataFrame(df_dim_cores)\n",
					"spark_dim_cores = spark_dim_cores.withColumn('core_id', crc32('core_id'))\n",
					"display(spark_dim_cores)"
				],
				"execution_count": 12
			},
			{
				"cell_type": "code",
				"source": [
					"launchpad_url = \"https://api.spacexdata.com/v4/launchpads\"\n",
					"headers = {\n",
					"    \"Content-Type\": \"application/json\"}\n",
					"\n",
					"response = requests.get(launchpad_url)\n",
					"launchpad_data = response.json()"
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"source": [
					"df_dim_launchpads = pd.json_normalize(launchpad_data)"
				],
				"execution_count": 14
			},
			{
				"cell_type": "code",
				"source": [
					"df_dim_launchpads.drop(columns=['images.large', 'launches', 'timezone', 'rockets'], axis=1, inplace=True)\n",
					"df_dim_launchpads"
				],
				"execution_count": 15
			},
			{
				"cell_type": "code",
				"source": [
					"landpad_url = \"https://api.spacexdata.com/v4/landpads\"\n",
					"headers = {\n",
					"    \"Content-Type\": \"application/json\"}\n",
					"\n",
					"response = requests.get(landpad_url)\n",
					"landpad_data = response.json()"
				],
				"execution_count": 16
			},
			{
				"cell_type": "code",
				"source": [
					"df_dim_landpads = pd.json_normalize(landpad_data)"
				],
				"execution_count": 17
			},
			{
				"cell_type": "code",
				"source": [
					"df_dim_landpads.drop(columns=['launches', 'wikipedia', 'images.large'], axis=1, inplace=True)\n",
					"df_dim_landpads"
				],
				"execution_count": 18
			},
			{
				"cell_type": "code",
				"source": [
					"rocket_url = \"https://api.spacexdata.com/v4/rockets\"\n",
					"headers = {\n",
					"    \"Content-Type\": \"application/json\"}\n",
					"\n",
					"response = requests.get(rocket_url)\n",
					"rocket_data = response.json()"
				],
				"execution_count": 19
			},
			{
				"cell_type": "code",
				"source": [
					"df_rockets = pd.json_normalize(rocket_data)"
				],
				"execution_count": 20
			},
			{
				"cell_type": "code",
				"source": [
					"df_dim_rockets = df_rockets[['name', 'type', 'active', 'stages', 'boosters', 'cost_per_launch', 'success_rate_pct', 'first_flight', 'country', 'company', 'description', 'id']]\n",
					"df_dim_rockets = df_dim_rockets.rename(columns={'id': 'rocket_id', 'type': 'rocket_type'})"
				],
				"execution_count": 21
			},
			{
				"cell_type": "code",
				"source": [
					"df_dim_rockets"
				],
				"execution_count": 22
			},
			{
				"cell_type": "code",
				"source": [
					"payload_url = \"https://api.spacexdata.com/v4/payloads\"\n",
					"headers = {\n",
					"    \"Content-Type\": \"application/json\"}\n",
					"\n",
					"response = requests.get(payload_url)\n",
					"payload_data = response.json()"
				],
				"execution_count": 23
			},
			{
				"cell_type": "code",
				"source": [
					"payload_data"
				],
				"execution_count": 24
			},
			{
				"cell_type": "code",
				"source": [
					"df_payloads = pd.json_normalize(\n",
					"    payload_data,\n",
					"    meta=[\n",
					"        'id',\n",
					"        'name',\n",
					"        'type',\n",
					"        'reused',\n",
					"        ['dragon', 'capsule'],\n",
					"        ['dragon', 'mass_returned_kg'],\n",
					"        ['dragon', 'flight_time_sec'],\n",
					"        ['dragon', 'water_landing'],\n",
					"        ['dragon', 'land_landing'],\n",
					"        'mass_kg',\n",
					"        'orbit',\n",
					"        'reference_system',\n",
					"        'regtime',\n",
					"        'longitude',\n",
					"        'semi_major_axis_km',\n",
					"        'eccentricity',\n",
					"        'periapsis_km',\n",
					"        'apoapsis_km',\n",
					"        'inclination_deg',\n",
					"        'period_min',\n",
					"        'lifespan_years',\n",
					"        'epoch',\n",
					"        'mean_motion',\n",
					"        'raan',\n",
					"        'arg_of_pericenter',\n",
					"        'mean_anomaly',\n",
					"        'id'\n",
					"    ],\n",
					"    sep='_',\n",
					"    errors='ignore'\n",
					")\n",
					"\n",
					"df_dim_payloads = df_payloads.explode('customers').reset_index(drop=True).explode('manufacturers').reset_index(drop=True).explode('nationalities').reset_index(drop=True).explode('norad_ids').reset_index(drop=True)\n",
					"\n",
					""
				],
				"execution_count": 25
			},
			{
				"cell_type": "code",
				"source": [
					"df_dim_payloads.drop('dragon_manifest', axis=1, inplace=True)\n",
					"df_dim_payloads.head(20)"
				],
				"execution_count": 26
			}
		]
	}
}